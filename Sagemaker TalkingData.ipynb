{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Overview </h1>\n",
    "\n",
    "[Link](https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/overview)\n",
    "\n",
    "Fraud risk is everywhere, but for companies that advertise online, click fraud can happen at an overwhelming volume, resulting in misleading click data and wasted money. Ad channels can drive up costs by simply clicking on the ad at a large scale. With over 1 billion smart mobile devices in active use every month, China is the largest\n",
    "mobile market in the world and therefore suffers from huge volumes of fraudulent traffic.\n",
    "\n",
    "TalkingData, China’s largest independent big data service platform, covers over 70% of active mobile devices nationwide. They handle 3 billion clicks per day, of which 90% are potentially fraudulent. Their current approach to prevent click fraud for app developers is to measure the journey of a user’s click across their portfolio, and flag IP addresses who produce lots of clicks, but never end up installing apps. With this information, they've built an IP blacklist and device blacklist.\n",
    "\n",
    "While successful, they want to always be one step ahead of fraudsters and have turned to the Kaggle community for help in further developing their solution. In their 2nd competition with Kaggle, you’re challenged to build an algorithm that predicts whether a user will download an app after clicking a mobile app ad. To support your modeling, they have provided a generous dataset covering approximately 200 million clicks over 4 days!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas can only determine what dtype a column should have once the whole file is read. \n",
    "# This means nothing can really be parsed before the whole file is read so don't guess dtypes here\n",
    "\n",
    "dtypes = dict(ip='int64', app='int64', device='int64', os='int64', channel='int64', click_time='object', is_attributed='int64')\n",
    "\n",
    "usecols = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from Amazon S3\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket = 'talkingdata-fraud'\n",
    "\n",
    "# Side note: I initially went through this exercise using only the sample csv which is much smaller than the actual train.csv.\n",
    "# After cleaning up the work flow, I was able to scale up the sagemaker instance appropriately for the data so that I would\n",
    "# not run into any more memory errors.\n",
    "\n",
    "# data_key = 'train_sample.csv'\n",
    "data_key = 'train.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket,data_key)\n",
    "\n",
    "# using the latter half of the training data for more recent data\n",
    "\n",
    "df = pd.read_csv(data_location, skiprows=range(1,123903891), nrows=61000000,\n",
    "                 usecols=usecols, dtype=dtypes, parse_dates=['click_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61000000 entries, 0 to 60999999\n",
      "Data columns (total 7 columns):\n",
      "ip               int64\n",
      "app              int64\n",
      "device           int64\n",
      "os               int64\n",
      "channel          int64\n",
      "click_time       datetime64[ns]\n",
      "is_attributed    int64\n",
      "dtypes: datetime64[ns](1), int64(6)\n",
      "memory usage: 3.2 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data fields</h1>\n",
    "\n",
    "Each row of the training data contains a click record, with the following features.\n",
    "\n",
    "\n",
    "* ip: ip address of click.\n",
    "* app: app id for marketing.\n",
    "* device: device type id of user mobile phone (e.g., iphone 6 plus, iphone 7, huawei mate 7, etc.)\n",
    "* os: os version id of user mobile phone\n",
    "* channel: channel id of mobile ad publisher\n",
    "* click_time: timestamp of click (UTC)\n",
    "* attributed_time: if user download the app for after clicking an ad, this is the time of the app download\n",
    "* is_attributed: the target that is to be predicted, indicating the app was downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>data type</th>\n",
       "      <th>percent missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ip</th>\n",
       "      <td>210014</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app</th>\n",
       "      <td>9</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device</th>\n",
       "      <td>1</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>os</th>\n",
       "      <td>13</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel</th>\n",
       "      <td>334</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click_time</th>\n",
       "      <td>2017-11-08 16:41:52</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_attributed</th>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            sample       data type  percent missing\n",
       "ip                          210014           int64              0.0\n",
       "app                              9           int64              0.0\n",
       "device                           1           int64              0.0\n",
       "os                              13           int64              0.0\n",
       "channel                        334           int64              0.0\n",
       "click_time     2017-11-08 16:41:52  datetime64[ns]              0.0\n",
       "is_attributed                    0           int64              0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sniff(df):\n",
    "    with pd.option_context(\"display.max_colwidth\", 20):\n",
    "        info = pd.DataFrame()\n",
    "        info['sample'] = df.iloc[0]\n",
    "        info['data type'] = df.dtypes\n",
    "        info['percent missing'] = df.isnull().sum()*100/len(df)\n",
    "        return info.sort_values('data type')\n",
    "\n",
    "sniff(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime to usable columns\n",
    "\n",
    "df['day'] = df['click_time'].dt.day# create train and test ofyear\n",
    "df['dayofweek'] = df['click_time'].dt.dayofweek\n",
    "df['hour'] = df['click_time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "      <th>clicks_per_ip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210014</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>334</td>\n",
       "      <td>2017-11-08 16:41:52</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2076</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>211</td>\n",
       "      <td>2017-11-08 16:41:52</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>15918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>296481</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>232</td>\n",
       "      <td>2017-11-08 16:41:52</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33473</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>245</td>\n",
       "      <td>2017-11-08 16:41:52</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>137</td>\n",
       "      <td>2017-11-08 16:41:52</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel          click_time  is_attributed  day  \\\n",
       "0  210014    9       1  13      334 2017-11-08 16:41:52              0    8   \n",
       "1    2076    3       1  32      211 2017-11-08 16:41:52              0    8   \n",
       "2  296481    9       1  19      232 2017-11-08 16:41:52              0    8   \n",
       "3   33473   15       1  13      245 2017-11-08 16:41:52              0    8   \n",
       "4  115014    3       1  13      137 2017-11-08 16:41:52              0    8   \n",
       "\n",
       "   dayofweek  hour  clicks_per_ip  \n",
       "0          2    16            616  \n",
       "1          2    16          15918  \n",
       "2          2    16            354  \n",
       "3          2    16           3030  \n",
       "4          2    16           1535  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting clicks by ip would probably be a good indicator of target\n",
    "\n",
    "ip_clicks = df.groupby(['ip']).count().reset_index()\n",
    "ip_clicks = ip_clicks[['ip','app']]\n",
    "ip_clicks.columns = ['ip', 'clicks_per_ip']\n",
    "df = pd.merge(df, ip_clicks, on='ip', how='left', sort=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ip_clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    60849867\n",
       "1      150133\n",
       "Name: is_attributed, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train and test split, set stratify = yes as the target is vastly disproportional \n",
    "# so that we can preserve the original percentages\n",
    "\n",
    "df['is_attributed'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Side note </h3>\n",
    "\n",
    "You may have noticed by now that I did not one-hot encode or .astype('category') on the categorical variables. OHE causes the instance to run into memory issues, and some reading has suggested that it is not vital in tree-based algorithms. Ideally the algorithm will see the categorical variables as multimodal and make decent splits anyways, so we'll see how the model performs. If anyone has any solutions to this issue other than not using Sagemaker built-in algorithms, please feel free to message me about it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# remember not to include IP from train and validation sets \n",
    "\n",
    "train_columns = ['app', 'device', 'os', 'channel', \n",
    "                'day', 'dayofweek', 'hour', 'clicks_per_ip']\n",
    "\n",
    "y = df.pop('is_attributed')\n",
    "\n",
    "X = df[train_columns]\n",
    "\n",
    "# del df\n",
    "\n",
    "# Train is for training model, val is used for validating the model, test is for testing the deployed model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10,stratify=y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train and validation data sets to a format per AWS documentation:\n",
    "# 1. Move the target attribute to the first position\n",
    "# 2. No index and headers\n",
    "\n",
    "pd.concat([y_train, X_train], axis=1).to_csv('xgb_train.csv', index=False, header=False)\n",
    "pd.concat([y_val, X_val], axis=1).to_csv('xgb_validation.csv', index=False, header=False)\n",
    "\n",
    "# Upload csv files to S3\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object('xgb_train.csv').upload_file('xgb_train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object('xgb_validation.csv').upload_file('xgb_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using the built-in XGBoost algorithm\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/xgb_train.csv'.format(bucket), content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/xgb_validation.csv'.format(bucket), content_type='csv')\n",
    "\n",
    "\n",
    "# Create a training job name\n",
    "job_name = 'talkingdata-xgboost-job-{}'.format(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost', '0.90-1')\n",
    "\n",
    "# Store model artifact in the s3 bucket\n",
    "output_location = 's3://{}/xgboost_output'.format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-05 21:54:09 Starting - Starting the training job...\n",
      "2020-03-05 21:54:12 Starting - Launching requested ML instances......\n",
      "2020-03-05 21:55:13 Starting - Preparing the instances for training...\n",
      "2020-03-05 21:55:55 Downloading - Downloading input data...\n",
      "2020-03-05 21:56:28 Training - Downloading the training image..\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\n",
      "2020-03-05 21:56:48 Training - Training image download completed. Training in progress.\u001b[34m[21:56:59] 43920000x8 matrix with 351360000 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[21:57:01] 10980000x8 matrix with 87840000 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 43920000 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 10980000 rows\u001b[0m\n",
      "\u001b[34m[21:57:01] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\u001b[0m\n",
      "\n",
      "2020-03-05 21:58:09 Uploading - Uploading generated training model\n",
      "2020-03-05 21:58:09 Completed - Training job completed\n",
      "\u001b[34m[0]#011train-auc:0.932636#011validation-auc:0.934052\u001b[0m\n",
      "Training seconds: 134\n",
      "Billable seconds: 134\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.2xlarge',\n",
    "                                    output_path=output_location,\n",
    "                                    sagemaker_session=sess)\n",
    "\n",
    "# Remember to set objective and evaluation metric to a parameter appropriate for our target\n",
    "# We will be using area under the curve for evaluation as this is a classification problem\n",
    "\n",
    "xgb.set_hyperparameters(objective='binary:logistic', eval_metric='auc', num_round = 1)\n",
    "\n",
    "data_channels = {\n",
    "    'train':s3_input_train,\n",
    "    'validation':s3_input_validation\n",
    "}\n",
    "\n",
    "xgb.fit(data_channels, job_name = job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the auc score is .934, which is generally considered outstanding, without one hot encoding the categorical variables too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "model = xgb.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_deserializer, csv_serializer\n",
    "\n",
    "model.content_type = 'text/csv'\n",
    "model.serializer = csv_serializer\n",
    "model.deserializer = None\n",
    "\n",
    "\n",
    "\n",
    "test_X = X_test.values\n",
    "\n",
    "# Not sure why connection is ending prematurely for predictions and would only accept around 1/100 of the test data at a time\n",
    "# If anyone knows how to fix this issue, please feel free to email me! This is my current workaround:\n",
    "\n",
    "block_size = len(test_X)//100\n",
    "\n",
    "\n",
    "def predict_decode_test(test_data):\n",
    "    results = model.predict(test_data)\n",
    "    # Results are returned as bytes so we need to decode it\n",
    "    results = np.fromstring(results.decode('utf-8'), sep=',')\n",
    "    return results\n",
    "\n",
    "results = np.array([])\n",
    "for num in range(100):\n",
    "    start = block_size*num\n",
    "    end = block_size*(num+1)\n",
    "    results = np.append(results,predict_decode_test(test_X[start:end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9978390163934426\n",
      "precision: 0.6629873598006053\n",
      "recall: 0.24805168853660162\n",
      "auc score: 0.6238702975103537\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In-depth look at our precision and accuracy score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "threshold = 0.50\n",
    "predicted = results >= threshold\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "precision = precision_score(y_test, predicted)\n",
    "recall = recall_score(y_test, predicted)\n",
    "auc = roc_auc_score(y_test, predicted)\n",
    "\n",
    "print(\"accuracy:\", accuracy)\n",
    "print(\"precision:\", precision)\n",
    "print(\"recall:\", recall)\n",
    "\n",
    "mat = confusion_matrix(y_test, predicted)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "\n",
    "print(\"auc score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Final Thoughts</h3>\n",
    "\n",
    "This exercise should demonstrate how to train and deploy a model without the need of a local machine. Interesting to note that my data for testing the deployed model has a significant lower auc score than the validation auc score. I would investigate this further to find out why that is when the validation data yields a higher score during training, unless it's just a matter of the target inequality.\n",
    "\n",
    "There are probably more interesting features that I can extract from the data, such as time between clicks for IPs or performing cartesian product transformations on the app/device/os variables.\n",
    "\n",
    "Another algorithm could also be used to increase the AUC score such as LightGBM which allows you to select columns as categorical for one of its parameters. It is unfortunate that AWS does not have LGBM as a built-in algorithm for Sagemaker, but we can use ECS to load our own algorithms or simply install it in Jupyter if you don't require the ability of scaling instances for training.\n",
    "\n",
    "Lastly, it is possible to grid search through a wide range of parameters and values and run training jobs in parallel with each other to optimize the model, but this is all coming out of my pocket and I'm not trying to incur too much costs with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
